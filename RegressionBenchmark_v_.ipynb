{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boristrs/seq2seq-fingerprint_MI/blob/master/RegressionBenchmark_v_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepchem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "RE5mm1TgwCHL",
        "outputId": "d7272e84-f3e0-42dd-8a57-39beda753b47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.7.1-py3-none-any.whl (693 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/693.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/693.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m686.1/693.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.2/693.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Collecting scipy<1.9 (from deepchem)\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit (from deepchem)\n",
            "  Downloading rdkit-2023.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.21 (from deepchem)\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2023.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n",
            "Installing collected packages: numpy, scipy, rdkit, deepchem\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.4.23 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "jaxlib 0.4.23+cuda12.cudnn89 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepchem-2.7.1 numpy-1.24.4 rdkit-2023.9.5 scipy-1.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "05c5663f9b35402f9dabc8090cdacb9a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric pytorch_lightning\n",
        "#!pip install tensorflow==1.4.1\n",
        "#!pip install haiku"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr5heJ2IxhrC",
        "outputId": "11dc40d9-edcb-48ff-fc62-957d22decc1e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.2.0.post0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.24.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.9.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.10.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.4.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.16.0rc0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.4.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t-cJ-S3vzPZ",
        "outputId": "50bee71c-a780-4487-89ac-a81f738a5c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import deepchem as dc\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "from deepchem.feat import Featurizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/boristrs/seq2seq-fingerprint_MI.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0rDW_fFx3lb",
        "outputId": "a75e674d-6cc1-4323-afab-2115fb8319ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'seq2seq-fingerprint_MI' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ZVkYMa220q",
        "outputId": "e87583cb-f14a-4a77-a420-414d59659f1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "aiohttp==3.9.3\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.16\n",
            "albumentations==1.3.1\n",
            "altair==4.2.2\n",
            "annotated-types==0.6.0\n",
            "anyio==3.7.1\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.5.0\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.0\n",
            "attrs==23.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.14.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bidict==0.23.0\n",
            "bigframes==0.21.0\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.3.4\n",
            "bqplot==0.12.42\n",
            "branca==0.7.1\n",
            "build==1.0.3\n",
            "CacheControl==0.14.0\n",
            "cachetools==5.3.2\n",
            "catalogue==2.0.10\n",
            "certifi==2024.2.2\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.85\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpathlib==0.16.0\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.9\n",
            "cmdstanpy==1.2.1\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.4\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.0\n",
            "cryptography==42.0.3\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.3\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.8\n",
            "dask==2023.8.1\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.2.0\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "deepchem==2.7.1\n",
            "defusedxml==0.7.1\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docutils==0.18.1\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.9.2\n",
            "earthengine-api==0.1.390\n",
            "easydict==1.12\n",
            "ecos==2.0.13\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.7.0\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.2.0\n",
            "fastai==2.7.14\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.19.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.13.1\n",
            "fiona==1.9.5\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==23.5.26\n",
            "flax==0.8.1\n",
            "folium==0.14.0\n",
            "fonttools==4.49.0\n",
            "frozendict==2.4.0\n",
            "frozenlist==1.4.1\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.6.4\n",
            "gdown==4.7.3\n",
            "geemap==0.31.0\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.4.0\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.2.0\n",
            "google-cloud-aiplatform==1.42.1\n",
            "google-cloud-bigquery==3.12.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.24.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.14.1\n",
            "google-cloud-language==2.13.1\n",
            "google-cloud-resource-manager==1.12.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=afaea4d3ec4850f813e15f2af87c8a7290f8cb98b1a248a0f584c829bef8bc56\n",
            "google-crc32c==1.5.0\n",
            "google-generativeai==0.3.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.0\n",
            "googleapis-common-protos==1.62.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==3.0.3\n",
            "grpc-google-iam-v1==0.13.0\n",
            "grpcio==1.60.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.42\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "huggingface-hub==0.20.3\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==7.1.0\n",
            "idna==3.6\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.4.9\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==7.0.1\n",
            "importlib-resources==6.1.1\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "intel-openmp==2023.2.3\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.18.2\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.23\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=8e42000672599e7ec0ea7f551acfcc95dcdd0e22b05a1d1f12f97b56a9fce4a8\n",
            "jeepney==0.7.1\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.3\n",
            "joblib==1.3.2\n",
            "jsonpickle==3.0.2\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.12.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.1\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.10\n",
            "kaggle==1.5.16\n",
            "kagglehub==0.1.9\n",
            "keras==2.15.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langcodes==3.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.3\n",
            "libclang==16.0.6\n",
            "librosa==0.10.1\n",
            "lightgbm==4.1.0\n",
            "lightning-utilities==0.10.1\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.4\n",
            "malloy==2023.1067\n",
            "Markdown==3.5.2\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.10\n",
            "mdit-py-plugins==0.4.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.7\n",
            "multidict==6.0.5\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.0.0\n",
            "nbclient==0.9.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.9.2\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.2.1\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.58.1\n",
            "numexpr==2.9.0\n",
            "numpy==1.24.4\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.9.0.80\n",
            "openpyxl==3.1.2\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.9\n",
            "orbax-checkpoint==0.4.4\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.19.2\n",
            "pandas-stubs==1.5.3.230304\n",
            "pandocfilters==1.5.1\n",
            "panel==1.3.8\n",
            "param==2.0.2\n",
            "parso==0.8.3\n",
            "parsy==2.1\n",
            "partd==1.4.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.6\n",
            "peewee==3.17.1\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pins==0.8.4\n",
            "pip-tools==6.13.0\n",
            "platformdirs==4.2.0\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.4.0\n",
            "polars==0.20.2\n",
            "pooch==1.8.0\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.9.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus_client==0.20.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.43\n",
            "prophet==1.1.5\n",
            "proto-plus==1.23.0\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==14.0.2\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.5.1\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==2.6.1\n",
            "pydantic_core==2.16.2\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.1\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.7.2\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.0.0\n",
            "pyparsing==3.1.1\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.0.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.14.2\n",
            "pytest==7.4.4\n",
            "python-apt @ file:///backend-container/containers/python_apt-0.0.0-cp310-cp310-linux_x86_64.whl#sha256=b209c7165d6061963abe611492f8c91c3bcef4b7a6600f966bab58900c63fefa\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.8.2\n",
            "pytorch-lightning==2.2.0.post0\n",
            "pytz==2023.4\n",
            "pyviz_comms==3.0.1\n",
            "PyWavelets==1.5.0\n",
            "PyYAML==6.0.1\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7.post0\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "rdkit==2023.9.5\n",
            "referencing==0.33.0\n",
            "regex==2023.12.25\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.5.0\n",
            "rich==13.7.0\n",
            "rpds-py==0.18.0\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.2\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.8.1\n",
            "scooby==0.9.2\n",
            "scs==3.2.4.post1\n",
            "seaborn==0.13.1\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.2\n",
            "sentencepiece==0.1.99\n",
            "shapely==2.0.3\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.7.4\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.8\n",
            "sphinxcontrib-devhelp==1.0.6\n",
            "sphinxcontrib-htmlhelp==2.0.5\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.7\n",
            "sphinxcontrib-serializinghtml==1.1.10\n",
            "SQLAlchemy==2.0.27\n",
            "sqlglot==19.9.0\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.8\n",
            "stanio==0.3.0\n",
            "statsmodels==0.14.1\n",
            "sympy==1.12\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.11.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.2.3\n",
            "tensorboard==2.15.2\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.15.0\n",
            "tensorflow-datasets==4.9.4\n",
            "tensorflow-estimator==2.15.0\n",
            "tensorflow-gcs-config==2.15.0\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.36.0\n",
            "tensorflow-metadata==1.14.0\n",
            "tensorflow-probability==0.23.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.4.0\n",
            "terminado==0.18.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-keras==2.15.0\n",
            "tf-slim==1.1.0\n",
            "thinc==8.2.3\n",
            "threadpoolctl==3.3.0\n",
            "tifffile==2024.2.12\n",
            "tinycss2==1.2.1\n",
            "tokenizers==0.15.2\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121/torch-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=0d4e8c52a1fcf5ed6cfc256d9a370fcf4360958fc79d0b08a51d55e70914df46\n",
            "torch_geometric==2.5.0\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.1.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=676bda4042734eda99bc59b2d7f761f345d3cde0cad492ad34e3aefde688c6d8\n",
            "torchdata==0.7.0\n",
            "torchmetrics==1.3.1\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.16.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.16.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=e76e78d0ad43636c9884b3084ffaea8a8b61f21129fbfa456a5fe734f0affea9\n",
            "tornado==6.3.2\n",
            "tqdm==4.66.2\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.37.2\n",
            "triton==2.1.0\n",
            "tweepy==4.14.0\n",
            "typer==0.9.0\n",
            "types-pytz==2024.1.0.20240203\n",
            "types-setuptools==69.1.0.20240223\n",
            "typing_extensions==4.9.0\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wasabi==1.1.2\n",
            "wcwidth==0.2.13\n",
            "weasel==0.3.4\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.7.0\n",
            "Werkzeug==3.0.1\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.3\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.7.0\n",
            "xgboost==2.0.3\n",
            "xlrd==2.0.1\n",
            "xxhash==3.4.1\n",
            "xyzservices==2023.10.1\n",
            "yarl==1.9.4\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.36\n",
            "zict==3.0.0\n",
            "zipp==3.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Bj0zNaoxvzPb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/seq2seq-fingerprint_MI\")\n",
        "\n",
        "from unsupervised.seq2seq_model import FingerprintFetcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": true,
        "id": "Isbrg8-KvzPb"
      },
      "outputs": [],
      "source": [
        "# Define our seq2seq featurizer.\n",
        "\n",
        "from rdkit import Chem\n",
        "\n",
        "class Seq2seqFeaturizer(Featurizer):\n",
        "    \"\"\"Seq2seq Featurizer.\"\"\"\n",
        "\n",
        "    def __init__(self, model_dir, vocab_dir):\n",
        "        \"\"\"Define the seq2seq feature.\"\"\"\n",
        "        self.fetcher = FingerprintFetcher(model_dir, vocab_dir)\n",
        "\n",
        "    def _featurize(self, mol):\n",
        "        \"\"\"\n",
        "        Calculate features for a single molecule.\n",
        "        Parameters\n",
        "        ----------\n",
        "        mol : RDKit Mol\n",
        "            Molecule.\n",
        "        \"\"\"\n",
        "        # This is a bit hacky. I have no idea why we have to start from mol instead of original smile.\n",
        "        smile = Chem.MolToSmiles(mol)\n",
        "        fp, _ = self.fetcher.decode(smile)\n",
        "        return fp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8BwzC4NBAXN",
        "outputId": "25ced765-d240-4ab7-f0d3-4f3b7feea451"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "qOjAiAmRvzPc",
        "outputId": "8abe3fef-3ab2-4c77-bade-2007febcffa9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'contrib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-80f850e5f858>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model directory and vocab directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeaturizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2seqFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/initialisation/test/gru-4-256\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/initialisation/pretrain/pm2.vocab\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-341bcdb01225>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_dir, vocab_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"\"\"Define the seq2seq feature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFingerprintFetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_featurize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/seq2seq-fingerprint_MI/unsupervised/seq2seq_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_dir, vocab_path, sess)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# Load tensorflow model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2SeqModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/seq2seq-fingerprint_MI/unsupervised/seq2seq_model.py\u001b[0m in \u001b[0;36mload_model_from_dir\u001b[0;34m(cls, train_dir, forward_only, sess)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weights/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model_to_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/seq2seq-fingerprint_MI/unsupervised/seq2seq_model.py\u001b[0m in \u001b[0;36mload_model_from_files\u001b[0;34m(cls, model_file, checkpoint_dir, forward_only, sess)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model_from_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"\"\"Load model from file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_base_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading seq2seq model definition from %s...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/seq2seq-fingerprint_MI/unsupervised/base_hparams.py\u001b[0m in \u001b[0;36mbuild_base_hparams\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#def build_base_hparams():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#    \"\"\"build hyper-parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;31m#    hparams = tf.compat.v1.estimator.training.HParams(dropout_rate=0.5,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#                                          num_layers=3,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#                                          size=128,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
          ]
        }
      ],
      "source": [
        "# Initailize the featurizer and cache it.\n",
        "sess = tf.compat.v1.InteractiveSession()\n",
        "#model directory and vocab directory\n",
        "featurizer = Seq2seqFeaturizer(\"/content/initialisation/test/gru-4-256\", \"/content/initialisation/pretrain/pm2.vocab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HirkbwmEvzPd"
      },
      "outputs": [],
      "source": [
        "# Build up specific model builder.\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR, NuSVR\n",
        "# Building scikit random forest model\n",
        "\n",
        "# Use this class to select different models for different task/dataset/split.\n",
        "class SKLearnModelSelector(object):\n",
        "\n",
        "    DATASET_MAPPING = {\n",
        "        \"delaney\": {\n",
        "            \"index\": (RandomForestRegressor, {}),\n",
        "            \"random\": (RandomForestRegressor, {}),\n",
        "            \"scaffold\": (RandomForestRegressor, {})\n",
        "        },\n",
        "        \"sampl\": {\n",
        "            \"index\": (RandomForestRegressor, {}),\n",
        "            \"random\": (RandomForestRegressor, {}),\n",
        "            \"scaffold\": (RandomForestRegressor, {})\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def __init__(self, dataset, split):\n",
        "        \"\"\"Input dataset and split.\"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.split = split\n",
        "\n",
        "    def __call__(self, task):\n",
        "        model_class, model_hparam = self.DATASET_MAPPING[self.dataset][self.split]\n",
        "        sklearn_model = model_class(**model_hparam)\n",
        "        return dc.models.sklearn_models.SklearnModel(sklearn_model, task)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44cfDeOcvzPe",
        "outputId": "ab674bda-55c4-4d8d-c1a5-41864e5f1041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Dataset: delaney, split: index\n",
            "-------------------------------------\n",
            "Loading dataset: delaney\n",
            "-------------------------------------\n",
            "Splitting function: index\n",
            "About to featurize Delaney dataset.\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from /tmp/delaney-processed.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 50.006 s\n",
            "TIMING: dataset construction took 50.163 s\n",
            "Loading dataset from disk.\n",
            "About to transform data\n",
            "TIMING: dataset construction took 0.174 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.144 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.038 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.040 s\n",
            "Loading dataset from disk.\n",
            "About to initialize singletask to multitask model\n",
            "Initializing directory for task measured log solubility in mols per litre\n",
            "About to create task-specific datasets\n",
            "Splitting multitask dataset into singletask datasets\n",
            "TIMING: dataset construction took 0.001 s\n",
            "Loading dataset from disk.\n",
            "Processing shard 0\n",
            "\tTask measured log solubility in mols per litre\n",
            "Dataset for task measured log solubility in mols per litre has shape ((902, 1024), (902, 1), (902, 1), (902,))\n",
            "Fitting model for task measured log solubility in mols per litre\n",
            "computed_metrics: [0.94448420122904553]\n",
            "computed_metrics: [0.66876784364694708]\n",
            "computed_metrics: [0.51629442708305984]\n",
            "({'mean-pearson_r2_score': 0.94448420122904553}, {'mean-pearson_r2_score': 0.66876784364694708}, {'mean-pearson_r2_score': 0.51629442708305984})\n",
            "t = 2.8410081863\n",
            "================================================================================\n",
            "================================================================================\n",
            "Dataset: delaney, split: random\n",
            "-------------------------------------\n",
            "Loading dataset: delaney\n",
            "-------------------------------------\n",
            "Splitting function: random\n",
            "About to featurize Delaney dataset.\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from /tmp/delaney-processed.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 49.728 s\n",
            "TIMING: dataset construction took 49.883 s\n",
            "Loading dataset from disk.\n",
            "About to transform data\n",
            "TIMING: dataset construction took 0.175 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.144 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.038 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.040 s\n",
            "Loading dataset from disk.\n",
            "About to initialize singletask to multitask model\n",
            "Initializing directory for task measured log solubility in mols per litre\n",
            "About to create task-specific datasets\n",
            "Splitting multitask dataset into singletask datasets\n",
            "TIMING: dataset construction took 0.001 s\n",
            "Loading dataset from disk.\n",
            "Processing shard 0\n",
            "\tTask measured log solubility in mols per litre\n",
            "Dataset for task measured log solubility in mols per litre has shape ((902, 1024), (902, 1), (902, 1), (902,))\n",
            "Fitting model for task measured log solubility in mols per litre\n",
            "computed_metrics: [0.93810698172594742]\n",
            "computed_metrics: [0.60317635661390367]\n",
            "computed_metrics: [0.62178963466087722]\n",
            "({'mean-pearson_r2_score': 0.93810698172594742}, {'mean-pearson_r2_score': 0.60317635661390367}, {'mean-pearson_r2_score': 0.62178963466087722})\n",
            "t = 2.8439941406\n",
            "================================================================================\n",
            "================================================================================\n",
            "Dataset: delaney, split: scaffold\n",
            "-------------------------------------\n",
            "Loading dataset: delaney\n",
            "-------------------------------------\n",
            "Splitting function: scaffold\n",
            "About to featurize Delaney dataset.\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from /tmp/delaney-processed.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "Featurizing sample 1000\n",
            "TIMING: featurizing shard 0 took 49.685 s\n",
            "TIMING: dataset construction took 49.841 s\n",
            "Loading dataset from disk.\n",
            "About to transform data\n",
            "TIMING: dataset construction took 0.175 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.145 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.038 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.039 s\n",
            "Loading dataset from disk.\n",
            "About to initialize singletask to multitask model\n",
            "Initializing directory for task measured log solubility in mols per litre\n",
            "About to create task-specific datasets\n",
            "Splitting multitask dataset into singletask datasets\n",
            "TIMING: dataset construction took 0.001 s\n",
            "Loading dataset from disk.\n",
            "Processing shard 0\n",
            "\tTask measured log solubility in mols per litre\n",
            "Dataset for task measured log solubility in mols per litre has shape ((902, 1024), (902, 1), (902, 1), (902,))\n",
            "Fitting model for task measured log solubility in mols per litre\n",
            "computed_metrics: [0.94743324181477984]\n",
            "computed_metrics: [0.54441442570895149]\n",
            "computed_metrics: [0.54346957507725302]\n",
            "({'mean-pearson_r2_score': 0.94743324181477984}, {'mean-pearson_r2_score': 0.54441442570895149}, {'mean-pearson_r2_score': 0.54346957507725302})\n",
            "t = 2.7897939682\n",
            "================================================================================\n",
            "================================================================================\n",
            "Dataset: sampl, split: index\n",
            "-------------------------------------\n",
            "Loading dataset: sampl\n",
            "-------------------------------------\n",
            "Splitting function: index\n",
            "About to featurize SAMPL dataset.\n",
            "About to load MUV dataset.\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from /tmp/SAMPL.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 20.627 s\n",
            "TIMING: dataset construction took 20.716 s\n",
            "Loading dataset from disk.\n",
            "About to transform data\n",
            "TIMING: dataset construction took 0.101 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.085 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.022 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.022 s\n",
            "Loading dataset from disk.\n",
            "About to initialize singletask to multitask model\n",
            "Initializing directory for task expt\n",
            "About to create task-specific datasets\n",
            "Splitting multitask dataset into singletask datasets\n",
            "TIMING: dataset construction took 0.001 s\n",
            "Loading dataset from disk.\n",
            "Processing shard 0\n",
            "\tTask expt\n",
            "Dataset for task expt has shape ((514, 1024), (514, 1), (514, 1), (514,))\n",
            "Fitting model for task expt\n",
            "computed_metrics: [0.93647812897873484]\n",
            "computed_metrics: [0.34471387480586863]\n",
            "computed_metrics: [0.63188951260318715]\n",
            "({'mean-pearson_r2_score': 0.93647812897873484}, {'mean-pearson_r2_score': 0.34471387480586863}, {'mean-pearson_r2_score': 0.63188951260318715})\n",
            "t = 1.4533848763\n",
            "================================================================================\n",
            "================================================================================\n",
            "Dataset: sampl, split: random\n",
            "-------------------------------------\n",
            "Loading dataset: sampl\n",
            "-------------------------------------\n",
            "Splitting function: random\n",
            "About to featurize SAMPL dataset.\n",
            "About to load MUV dataset.\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from /tmp/SAMPL.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 20.501 s\n",
            "TIMING: dataset construction took 20.590 s\n",
            "Loading dataset from disk.\n",
            "About to transform data\n",
            "TIMING: dataset construction took 0.103 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.082 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.022 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.022 s\n",
            "Loading dataset from disk.\n",
            "About to initialize singletask to multitask model\n",
            "Initializing directory for task expt\n",
            "About to create task-specific datasets\n",
            "Splitting multitask dataset into singletask datasets\n",
            "TIMING: dataset construction took 0.001 s\n",
            "Loading dataset from disk.\n",
            "Processing shard 0\n",
            "\tTask expt\n",
            "Dataset for task expt has shape ((514, 1024), (514, 1), (514, 1), (514,))\n",
            "Fitting model for task expt\n",
            "computed_metrics: [0.92804336100873375]\n",
            "computed_metrics: [0.52560024868333433]\n",
            "computed_metrics: [0.60930886028759723]\n",
            "({'mean-pearson_r2_score': 0.92804336100873375}, {'mean-pearson_r2_score': 0.52560024868333433}, {'mean-pearson_r2_score': 0.60930886028759723})\n",
            "t = 1.4439690113\n",
            "================================================================================\n",
            "================================================================================\n",
            "Dataset: sampl, split: scaffold\n",
            "-------------------------------------\n",
            "Loading dataset: sampl\n",
            "-------------------------------------\n",
            "Splitting function: scaffold\n",
            "About to featurize SAMPL dataset.\n",
            "About to load MUV dataset.\n",
            "Loading raw samples now.\n",
            "shard_size: 8192\n",
            "About to start loading CSV from /tmp/SAMPL.csv\n",
            "Loading shard 1 of size 8192.\n",
            "Featurizing sample 0\n",
            "TIMING: featurizing shard 0 took 20.430 s\n",
            "TIMING: dataset construction took 20.520 s\n",
            "Loading dataset from disk.\n",
            "About to transform data\n",
            "TIMING: dataset construction took 0.101 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.082 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.025 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.024 s\n",
            "Loading dataset from disk.\n",
            "About to initialize singletask to multitask model\n",
            "Initializing directory for task expt\n",
            "About to create task-specific datasets\n",
            "Splitting multitask dataset into singletask datasets\n",
            "TIMING: dataset construction took 0.001 s\n",
            "Loading dataset from disk.\n",
            "Processing shard 0\n",
            "\tTask expt\n",
            "Dataset for task expt has shape ((514, 1024), (514, 1), (514, 1), (514,))\n",
            "Fitting model for task expt\n",
            "computed_metrics: [0.92621163407191043]\n",
            "computed_metrics: [0.54980201372197168]\n",
            "computed_metrics: [0.35005217569673097]\n",
            "({'mean-pearson_r2_score': 0.92621163407191043}, {'mean-pearson_r2_score': 0.54980201372197168}, {'mean-pearson_r2_score': 0.35005217569673097})\n",
            "t = 1.4496138096\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from deepchem.molnet.run_benchmark import load_dataset, benchmark_model\n",
        "from itertools import product\n",
        "\n",
        "metric = [dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean)]\n",
        "\n",
        "datasets = [\n",
        "    # 'kaggle', # does not allow featurizer input\n",
        "    'delaney', # we discard it here to save the testing time.\n",
        "    # 'nci', # Could be very large. discard it if we do not use it.\n",
        "    # 'chembl', # too long to run, discard.\n",
        "    'sampl'\n",
        "]\n",
        "splits = [\n",
        "    \"index\",\n",
        "    \"random\",\n",
        "    \"scaffold\"\n",
        "]\n",
        "\n",
        "for dataset, split in product(datasets, splits):\n",
        "    print(\"=\"*80)\n",
        "    print(\"Dataset: %s, split: %s\" % (dataset, split))\n",
        "    tasks, all_datasets, transformers = load_dataset(dataset, featurizer, split)\n",
        "    reg_model = dc.models.multitask.SingletaskToMultitask(tasks, SKLearnModelSelector(dataset, split))\n",
        "    train, val, test, t = benchmark_model(reg_model, all_datasets, transformers, metric, test=True)\n",
        "    print(train, val, test)\n",
        "    print(\"t = %.10f\" % t)\n",
        "    print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J6L2iHJzvzPf"
      },
      "outputs": [],
      "source": [
        "sess.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}